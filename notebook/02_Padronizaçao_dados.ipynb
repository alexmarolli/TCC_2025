{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T04:20:00.245924Z",
     "start_time": "2025-11-07T04:20:00.237237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from config import LIST_TICKETS\n",
    "\n",
    "print(f\"Ações disponíveis para treino: {LIST_TICKETS}\")\n",
    "# --- Configurações ---\n",
    "# REMOVEMOS AQUI A LINHA: TICKER_PARA_PROCESSAR = 'VALE3.SA'\n",
    "CAMINHO_DADOS_BRUTOS = \"../data/01_raw\"\n",
    "CAMINHO_DADOS_PROCESSADOS = \"../data/03_processed\"\n",
    "CAMINHO_MODELOS = \"../models\"\n",
    "\n",
    "# Parâmetros para o pré-processamento\n",
    "PERCENTUAL_TREINO = 0.8\n",
    "JANELA_DE_TEMPO = 60 # Usaremos 60 dias de histórico para prever o próximo\n",
    "\n",
    "# Garante que os diretórios de saída existam\n",
    "os.makedirs(CAMINHO_DADOS_PROCESSADOS, exist_ok=True)\n",
    "os.makedirs(CAMINHO_MODELOS, exist_ok=True)\n",
    "\n",
    "print(\"Configurações carregadas.\")"
   ],
   "id": "b77a8055a919257d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ações disponíveis para treino: ['PETR4.SA', 'VALE3.SA', 'ITUB4.SA']\n",
      "Configurações carregadas.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T04:20:00.501955Z",
     "start_time": "2025-11-07T04:20:00.313257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def processar_e_salvar_dados(ticker):\n",
    "    print(f\"\\n----- Iniciando Processamento para {ticker} -----\")\n",
    "\n",
    "    # 1. Carregamento dos dados\n",
    "    caminho_arquivo = os.path.join(CAMINHO_DADOS_BRUTOS, f\"{ticker}.csv\")\n",
    "    try:\n",
    "        # Importante: A coluna que contém o preço a ser previsto deve ser a ÚNICA selecionada.\n",
    "        # No seu log anterior, a coluna de fechamento (Close) era o índice 1 (Unnamed: 1).\n",
    "        df = pd.read_csv(\n",
    "            caminho_arquivo,\n",
    "            header=2,\n",
    "            index_col='Date',\n",
    "            parse_dates=True\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: Arquivo não encontrado em '{caminho_arquivo}'. Pulando.\")\n",
    "        return\n",
    "\n",
    "    # Tratamento de valores nulos (se houver) e Seleção da coluna\n",
    "    df.dropna(inplace=True)\n",
    "    # Selecionamos a coluna 1, que é o fechamento ajustado (Close)\n",
    "    dados_fechamento = df.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "    # 2. Divisão e Normalização\n",
    "    ponto_divisao = int(len(dados_fechamento) * PERCENTUAL_TREINO)\n",
    "    dados_treino = dados_fechamento[:ponto_divisao]\n",
    "    dados_teste = dados_fechamento[ponto_divisao:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(dados_treino)\n",
    "\n",
    "    dados_treino_normalizados = scaler.transform(dados_treino)\n",
    "    dados_teste_normalizados = scaler.transform(dados_teste)\n",
    "\n",
    "    # CORREÇÃO CRÍTICA: Salva o scaler no local CORRETO para o treinamento\n",
    "    caminho_scaler = os.path.join(CAMINHO_DADOS_PROCESSADOS, f\"{ticker}_scaler.joblib\")\n",
    "    joblib.dump(scaler, caminho_scaler)\n",
    "    print(f\"Scaler salvo com sucesso em: {caminho_scaler}\")\n",
    "\n",
    "    # 3. Criação das Sequências\n",
    "    def criar_sequencias(dados, janela_de_tempo):\n",
    "        X, y = [], []\n",
    "        for i in range(janela_de_tempo, len(dados)):\n",
    "            X.append(dados[i-janela_de_tempo:i, 0])\n",
    "            y.append(dados[i, 0])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X_train, y_train = criar_sequencias(dados_treino_normalizados, JANELA_DE_TEMPO)\n",
    "    X_test, y_test = criar_sequencias(dados_teste_normalizados, JANELA_DE_TEMPO)\n",
    "\n",
    "    # Ajusta o formato de X para ser [amostras, janelas, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # 4. Salvamento dos Arrays\n",
    "    np.save(os.path.join(CAMINHO_DADOS_PROCESSADOS, f'{ticker}_X_train.npy'), X_train)\n",
    "    np.save(os.path.join(CAMINHO_DADOS_PROCESSADOS, f'{ticker}_y_train.npy'), y_train)\n",
    "    np.save(os.path.join(CAMINHO_DADOS_PROCESSADOS, f'{ticker}_X_test.npy'), X_test)\n",
    "    np.save(os.path.join(CAMINHO_DADOS_PROCESSADOS, f'{ticker}_y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"Dados processados ({X_train.shape[0]} amostras de treino) foram salvos para {ticker}.\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO DO LOOP PRINCIPAL ---\n",
    "for ticker in LIST_TICKETS:\n",
    "    processar_e_salvar_dados(ticker)\n",
    "\n",
    "print(\"\\n\\n✅ Processamento de todos os Tickers concluído!\")"
   ],
   "id": "4f59972086322454",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Iniciando Processamento para PETR4.SA -----\n",
      "Scaler salvo com sucesso em: ../data/03_processed/PETR4.SA_scaler.joblib\n",
      "Dados processados (5129 amostras de treino) foram salvos para PETR4.SA.\n",
      "\n",
      "----- Iniciando Processamento para VALE3.SA -----\n",
      "Scaler salvo com sucesso em: ../data/03_processed/VALE3.SA_scaler.joblib\n",
      "Dados processados (5129 amostras de treino) foram salvos para VALE3.SA.\n",
      "\n",
      "----- Iniciando Processamento para ITUB4.SA -----\n",
      "Scaler salvo com sucesso em: ../data/03_processed/ITUB4.SA_scaler.joblib\n",
      "Dados processados (4927 amostras de treino) foram salvos para ITUB4.SA.\n",
      "\n",
      "\n",
      "✅ Processamento de todos os Tickers concluído!\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
